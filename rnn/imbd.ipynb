{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07e19b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data processing and deep learning\n",
    "\n",
    "import pandas as pd  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from torch.nn.utils.rnn import pad_sequence  # RNN padding sequences\n",
    "from collections import Counter              # For counting word frequencies\n",
    "import re                                    # Regular expressions for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81c8332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for model hyperparameters\n",
    "config = {\n",
    "    \"BATCH_SIZE\" : 64,   # Number of samples per batch\n",
    "    \"EMBED_DIM\" : 100,   # Dimension of word embeddings\n",
    "    \"HIDDEN_DIM\" : 128,  # Hidden state dimension for LSTM\n",
    "    \"EPOCHS\" : 5,        # Number of training epochs\n",
    "    \"MAX_VOCAB_SIZE\" : 20000,  # Maximum vocabulary size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c10355ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available, otherwise use CPU\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5129928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to convert text to tokens\n",
    "def tokenize(text):\n",
    "    \"\"\"Convert text to lowercase tokens, removing special characters.\"\"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # Remove special characters\n",
    "    return text.split()  # Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afc2e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from texts\n",
    "def build_vocab(texts, max_size):\n",
    "    \"\"\"Create vocabulary mapping from most common words.\"\"\"\n",
    "    # Count word frequencies\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(tokenize(text))\n",
    "\n",
    "    # Initialize vocab with special tokens\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1}  # padding and unknown tokens\n",
    "    # Add most common words up to max_size\n",
    "    for word, _ in counter.most_common(max_size - 2):\n",
    "        vocab[word] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "370a8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for loading IMDB sentiment data\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"Load sentiment reviews and encode them using vocabulary.\"\"\"\n",
    "    def __init__(self, csv_path, vocab):\n",
    "        # Read CSV file and extract reviews and sentiment labels\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.texts = df[\"review\"].values\n",
    "        self.labels = df[\"sentiment\"].values\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Convert text to indices using vocabulary.\"\"\"\n",
    "        # Map each token to its vocabulary index, use <unk> for unknown words\n",
    "        return torch.tensor(\n",
    "            [self.vocab.get(tok, self.vocab[\"<unk>\"]) for tok in tokenize(text)],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return dataset size.\"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return encoded text and sentiment label for given index.\"\"\"\n",
    "        # Convert sentiment string to numeric value: \"positive\" -> 1, \"negative\" -> 0\n",
    "        label = 1.0 if self.labels[idx] == \"positive\" else 0.0\n",
    "        return self.encode(self.texts[idx]), torch.tensor(label, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4779470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define padding index and batch collation function\n",
    "PAD_IDX = 0  # Padding token index\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Pad variable-length sequences in batch to same length.\"\"\"\n",
    "    # Separate texts and labels from batch\n",
    "    texts, labels = zip(*batch)\n",
    "    # Pad sequences to maximum length in batch\n",
    "    texts = pad_sequence(texts, padding_value=PAD_IDX)\n",
    "    # Stack labels into single tensor\n",
    "    labels = torch.stack(labels)\n",
    "    # Move to specified device (GPU/CPU)\n",
    "    return texts.to(DEVICE), labels.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "545d2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM-based model for sentiment classification\n",
    "class LSTMSentiment(nn.Module):\n",
    "    \"\"\"LSTM model for binary sentiment classification.\"\"\"\n",
    "    def __init__(self, vocab_size, config):\n",
    "        super().__init__()\n",
    "        # Embedding layer: converts word indices to dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, config[\"EMBED_DIM\"], padding_idx=PAD_IDX)\n",
    "        # LSTM layer: processes sequences and captures long-term dependencies\n",
    "        self.lstm = nn.LSTM(config[\"EMBED_DIM\"], config[\"HIDDEN_DIM\"])\n",
    "        # Fully connected layer: outputs single value for binary classification\n",
    "        self.fc = nn.Linear(config[\"HIDDEN_DIM\"], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: x shape [seq_len, batch]\"\"\"\n",
    "        # Convert indices to embeddings\n",
    "        emb = self.embedding(x)\n",
    "        # LSTM processes embeddings, returns hidden states\n",
    "        _, (hidden, _) = self.lstm(emb)\n",
    "        # Pass final hidden state through FC layer and squeeze to 1D\n",
    "        return self.fc(hidden[-1]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82b1c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and build vocabulary\n",
    "df = pd.read_csv('dataset/IMDB.csv')  # Load IMDB dataset\n",
    "vocab = build_vocab(df[\"review\"], config[\"MAX_VOCAB_SIZE\"])  # Build vocabulary from reviews\n",
    "\n",
    "# Create dataset and dataloader for training\n",
    "train_dataset = SentimentDataset(\"dataset/IMDB.csv\", vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"BATCH_SIZE\"], \n",
    "                          shuffle=True, collate_fn=collate_fn)  # Shuffle data and pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5408971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.6944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.6917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.6898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "model = LSTMSentiment(len(vocab), config).to(DEVICE)  # Fixed: Pass config to constructor\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Adam optimizer\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config[\"EPOCHS\"]):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    # Iterate through batches\n",
    "    for texts, labels in tqdm(train_loader):\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(texts)  # Get predictions\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80732869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function for sentiment prediction\n",
    "def predict(text):\n",
    "    \"\"\"Predict sentiment for given text.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        # Encode text using vocabulary\n",
    "        encoded = torch.tensor(\n",
    "            [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokenize(text)],\n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(1).to(DEVICE)  # Add batch dimension and move to device\n",
    "\n",
    "        # Get prediction probability\n",
    "        prob = torch.sigmoid(model(encoded)).item()\n",
    "        # Return sentiment label and probability\n",
    "        return \"positive\" if prob >= 0.5 else \"negative\", prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "902d22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing positive review:\n",
      "('negative', 0.41810593008995056)\n",
      "\n",
      "Testing negative review:\n",
      "('positive', 0.7637147903442383)\n"
     ]
    }
   ],
   "source": [
    "# Test predictions on sample reviews\n",
    "print(\"Testing positive review:\")\n",
    "print(predict(\"This movie was absolutely fantastic\"))\n",
    "print(\"\\nTesting negative review:\")\n",
    "print(predict(\"Worst acting and boring story\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cead2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
